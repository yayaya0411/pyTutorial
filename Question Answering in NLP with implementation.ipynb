{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Benchmarked Datasets for Question Answering in NLP with implementation in PyTorch, Keras, and TensorFlow\n",
    "ref:  \n",
    "https://analyticsindiamag.com/most-benchmarked-datasets-for-question-answering-in-nlp-with-implementation-in-pytorch-keras-and-tensorflow/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQuAD Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the SQuAD dataset using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torchnlp.download import download_file_maybe_extract\n",
    "def squad_dataset(directory='data/',\n",
    "                  train=False,\n",
    "                  dev=False,\n",
    "                  train_filename='train-v2.0.json',\n",
    "                  dev_filename='dev-v2.0.json',\n",
    "                  check_files_train=['train-v2.0.json'],\n",
    "                  check_files_dev=['dev-v2.0.json'],\n",
    "                  url_train='https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json',\n",
    "                  url_dev='https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json'\n",
    "                 ):\n",
    "    download_file_maybe_extract(url=url_dev, directory=directory, check_files=check_files_dev)\n",
    "    download_file_maybe_extract(url=url_train, directory=directory, check_files=check_files_train)\n",
    "    squad= []\n",
    "    splits_text = [(train, train_filename), (dev, dev_filename)]\n",
    "    splits_text = [f for (requested, f) in splits_text if requested]\n",
    "    for filename in splits_text :\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        with open(full_path, 'r') as temp:\n",
    "            ret.append(json.load(temp)['data'])\n",
    "    if len(squad) == 1:\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return tuple(squad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the SQuAD dataset using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def squad(path):\n",
    "  data = tf.data.TextLineDataset(path)\n",
    "  def content_filter(source):\n",
    "    return tf.logical_not(tf.strings.regex_full_match(\n",
    "        source, \n",
    "        '([[:space:]][=])+.+([[:space:]][=])+[[:space:]]*'))\n",
    "  data = data.filter(content_filter)\n",
    "  data = data.map(lambda x: tf.strings.split(x, ' . '))\n",
    "  data = data.unbatch()\n",
    "  return data\n",
    "train= squad('https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v2.0.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bAbI D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
